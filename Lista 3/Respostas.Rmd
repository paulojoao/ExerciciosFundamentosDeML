---
title: "Exercicio Computacional 1 e 2"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
  html_notebook: default
---



Exercicios Conceituais

## 1 - D
## 2 - C
## 3 - C
## 4 - C
## 5 - A
## 6 - C
## 7 - C


Carregando dependências
```{r messages=F, warning=F}
library(caret)
library(ROCR)
library(e1071)
library(datasets) 
library(skimr)
library(dplyr)
library(varhandle)
library(corrplot)
library(ggplot2)
library(MASS)
library(ROCR)
library(e1071)
```


## 1. Exercício 1 (Regressão Logística)
Considere o conjunto de dados iris, amplamente conhecido e usado como exemplo em diversos livros de
aprendizagem de máquina. Esse conjunto já vem incorporado em diversos pacotes das linguagens R e Python, de
acordo com
Linguagem R: library(datasets)
Linguagem Python: from sklearn import datasets
A partir do conjunto de dados carregado capture somente os dados relacionados com a classe virginica, que
consiste em uma espécie de uma planta (flor). O objetivo desse exercício é construir um classificador binário a
partir de um modelo de regressão logística, permitindo verificar se uma espécie a ser testada é ou não do tipo
virginica. Isso significa que um pré-processamento deve ser realizado sobre o dataset iris a fim de obtermos
apenas duas classes (e.g., 0 -> não é virginica e 1 -> é virginica).
As variáveis explanatórias desse conhecido dataset são:
• Petal.Length: comprimento da pétala da flor
• Petal.Width: largura da pétala da flor
• Sepal.Length: comprimento da sépala da flor
• Sepal.Width: largura da sépala da flor
• Questões Avaliativas
> 1) Realize o pré-processamento necessário para extração dos dados relacionados à classe virginica.

```{r}

dataset = iris

# Processando as classes para sua binarização do problema de classificação
# Objetivo: capturar as classes de interesse e atribuir 0 ou 1 para a espécie considerada no dataset
binary_species <- to.dummy(iris$Species, "species")
binary_species <- as.data.frame(binary_species)
unique(binary_species)


Species = binary_species$species.virginica
dataset = data.frame(dataset[,1:4],Species)

str(dataset)


# Atribuição do tipo fator à coluna especies (species) do dataset
cols <- c("Species")
dataset[cols] <- lapply(dataset[cols], factor)  ## as.factor() poderia ser usado

species_iris <- dataset$Species
species_iris
unique(species_iris)
size_dataset = dim(dataset)
```
> 2) Faça a análise de dados das variáveis explanatórias para o conjunto de dados.


```{r}
summary(iris)
```

Covariancia entre as variaveis.
```{r}
cov(iris[, 1:4])
```



```{r}
pairs(iris[,1:4],col=iris[,5],oma=c(4,4,6,12))
par(xpd=TRUE)
legend(0.85,0.6, as.vector(unique(iris$Species)),fill=c(1,2,3))
```


```{r}
irisVer <- subset(iris, Species == "versicolor")
irisSet <- subset(iris, Species == "setosa")
irisVir <- subset(iris, Species == "virginica")
par(mfrow=c(1,3),mar=c(6,3,2,1))
boxplot(irisVer[,1:4], main="Versicolor",ylim = c(0,8),las=2)
boxplot(irisSet[,1:4], main="Setosa",ylim = c(0,8),las=2)
boxplot(irisVir[,1:4], main="Virginica",ylim = c(0,8),las=2)
```

```{r}
parcoord(iris[,1:4], col=iris[,5],var.label=TRUE,oma=c(4,4,6,12))
par(xpd=TRUE)
legend(0.85,0.6, as.vector(unique(iris$Species)),fill=c(1,2,3))
```



```{r}
g <- ggplot(iris, aes(x = iris$Sepal.Length, y = iris$Sepal.Width))
g <- g + geom_point(aes(shape = factor(iris$Species), colour = factor(iris$Species)))
g <- g + ggtitle (" SepalLength Vs SepalWidth wrt Species" )
g <- g + stat_smooth(method= lm)
g
```


> 3) Realize a divisão do conjunto de treino e teste em 90/10.

```{r}
set.seed(50)
species_iris <- dataset$Species
species_iris
unique(species_iris)

# É fundamental checar as dimensões (tamanhos) dos datasets para o split (divisão)
# a função dim nos informa a quantidade de linhas e colunas do dataset
size_dataset = dim(dataset)

# Divisão - split de dataset em treino e teste (p é a porcentagem relacionada ao treinamento)
indices_treinamento <- createDataPartition(dataset$Species, p = 0.9, list = FALSE)

# Agora, vamos usar os �?ndices de treinamento para gerar o conjunto de dados de treinamento
dados_treinamento <-dataset[indices_treinamento,]
# Em seguida, podemos acessar diretamente o conjunto de teste
dados_teste <- dataset[-indices_treinamento,]
```


> 4) Para reprodução dos resultados use o set.seed(12).

```{r}
set.seed(12)
```

> 5) Forneça visualizações de dispersão e densidades das variáveis explanatórias de treino e as classes.

```{r}
# Gráfico de Dispersão com ggplot
ggplot(dados_treinamento, aes(x = dados_treinamento$Petal.Length, y = dados_treinamento$Petal.Width, color=Species)) + 
  geom_point() + 
  scale_color_discrete(name = "Legenda", labels = c("Não Virginica","Virginica"))+
  ylab('Width (largura)') + 
  xlab('Length (Comprimento)') + 
  ggtitle("Gráfico de DispersÃ£o")

```

```{r}
ggplot(data = dados_treinamento, aes(x=dados_treinamento$Petal.Length, fill= Species)) + 
  geom_density(alpha=.5) + 
  xlab('Comprimento (length)') +
  scale_fill_discrete(name = "Legenda", labels = c("Não Virginica","Virginica")) + 
  ggtitle("Gráfico de Densidades") 
```


```{r}
ggplot(data = dados_treinamento, aes(x=dados_treinamento$Petal.Width, fill= Species)) + 
  geom_density(alpha=.5) + 
  xlab('Largura (width)') +
  scale_fill_discrete(name = "Legenda", labels = c("Não Virginica","Virginica")) + 
  ggtitle("Gráfico de Densidades") 

```

```{r}
feature_dataframe    = dados_treinamento[,1:4]
matrix_corr_features = cor(feature_dataframe)
corrplot(matrix_corr_features, method = 'color')
```


> 6) Construa e treine o modelo preditivo de ML baseado em regressão logística.

```{r}
equation <- " Species ~ ."
equation <- as.formula(equation)

modelo_ML_logistic <- glm(equation, data = dados_treinamento, family = 'binomial')
plot(modelo_ML_logistic)
```

> 7) Faça a síntese do modelo e interprete os seus resultados.

```{r}
summary(modelo_ML_logistic)
```

> 8) Encontre as variáveis explanatórias mais relevantes para o modelo.

```{r}
varImpl <- varImp(modelo_ML_logistic)
print(varImpl)
```


> 9) Faça as predições para os dados de teste e avalie os resultados


```{r}
previsao_teste <- predict(modelo_ML_logistic, dados_teste, type="response")
previsao_teste <- round(as.numeric(previsao_teste))
previsao_teste <- as.factor(previsao_teste)

dados_teste_fatores = as.factor(dados_teste$Species)
previsao_teste_data <- data.frame(previsao_teste, dados_teste_fatores)
confusionMatrix(data = previsao_teste, reference = dados_teste_fatores, positive = "1")

# Cômputo da acurácia
accuracy <- mean(dados_teste_fatores == previsao_teste)
accuracy

```
```{r}
previsao_teste_data
```


> 10) A partir dos novos dados de entrada colocados abaixo, realize as classificações com o modelo

```{r}
flor1 <- data.frame(Sepal.Length=6.4, Sepal.Width=2.8, Petal.Length=4.6, Petal.Width=1.8)
flor2 <- data.frame(Sepal.Length=6.3, Sepal.Width=2.5, Petal.Length=4.1, Petal.Width=1.7)

pred_flor1 <- predict(modelo_ML_logistic, flor1, type = 'response')
pred_flor2 <- predict(modelo_ML_logistic, flor2, type = 'response')
pred_flor1
pred_flor2
```

## 2) Considere o desenvolvimento do modelo de classificação do Exercício Computacional 1 - obtenha a matriz de
confusão do classificador. O ponto chave aqui é realizar a interpretação dos resultados obtidos.

```{r}
confusionMatrix(data = previsao_teste, reference = dados_teste_fatores, positive = "1")
```

> O modelo consegueiu uma acuracia exelente 94%. e o modelo conseguiu classificar corretamente 9 positivos. e não deu nenhum falso negativo.


## Exercicio 3 - Exercício 3 (Regressão Logística)

Uma instituição financeira nos forneceu um conjunto de dados relacionados à créditos financeiros presentes no
banco de dados da instituição. A instituição está trabalhando em um projeto de ciência de dados para previsão
de risco de crédito. Nós iremos participar de uma fase específica desse projeto com o objetivo de construir um
classificador, que possa auxiliar na análise de risco de crédito de diversos clientes da instituição.
O modelo de ML (i.e., classificador) deve prever se um determinado cliente deve ou não receber créditos de
produtos financeiros ofertados pela instituição. Isso significa que teremos acesso a um conjunto de dados com
informações diversas sobre inúmeros clientes da instituição.
O conjunto de dados consiste em vinte (20) variáveis explanatórias que consistem em informações diversas sobre
os clientes incluindo: duração e tamanho do crédito, indicadores de saldo e operações financeiras, além de dados
dos clientes como idade, dependentes, emprego e até contatos como telefone. Tais informações são apresentadas
com codificação que são processadas pela instituição para posteriores interpretações. Com isso, nossa tarefa
consiste em lidar com os dados codificados e a variável de saída credit.rating, que indica o estado de aprovação
(1) ou desaprovação (0) de crédito para cada dados de treinamento (registro) do dataset.
Os pacotes listados abaixo serão fundamentais para as questões avaliativas:
• library(caret)
• library(ROCR)
• library(e1071)

> 1) Realize a importação do arquivo .csv fornecido para o RStudio

```{r}
dataset_credito <- read.csv('credit_dataset.csv', sep = ',')
```


> 2) Faça a análise exploratória do dataset e verifique:

```{r}
summary(dataset_credito)
str(dataset_credito)

M = cor(dataset_credito)
corrplot(M, method="square")
```


> i) a necessidade de normalização dos dados
Adicionando uma função para normalizar os dados


> ii) conversão para fatores
Adicionando função para conversão de variáveis em fatores


> 3) Considerando o item 2) identifique quais são as variáveis numéricas e os fatores.

Variveis numéricas: "credit.duration.months", "age", "credit.amount".
Variaveis categoricas: 'credit.rating', 'account.balance', 'previous.credit.payment.status',
                      'credit.purpose', 'savings', 'employment.duration', 'installment.rate',
                      'marital.status', 'guarantor', 'residence.duration', 'current.assets',
                      'other.credits', 'apartment.type', 'bank.credits', 'occupation', 
                      'dependents', 'telephone', 'foreign.worker'

> Crie duas funções: para normalização e conversão em fatores.

```{r}
factor_conversion <- function(df , variaveis){
  # Loop para todas as variáveis
  for (variavel in variaveis){
  # Conversão para fator
  df[[variavel]] <- as.factor(df[[variavel]])
  }
  return(df)
}

normalizar_features <- function(df, variables){
  for (variable in variables){
    df[[variable]] <- scale(df[[variable]], center = T, scale = T)
  }
  return(df)
}

numeric_vars <- c("credit.duration.months", "age", "credit.amount")

# Aplicação da normalização das variáveis a partir se duas identificações
dataset_credito_normalizado <- normalizar_features(dataset_credito, numeric_vars)


categorical_vars <- c('credit.rating', 'account.balance', 'previous.credit.payment.status',
                      'credit.purpose', 'savings', 'employment.duration', 'installment.rate',
                      'marital.status', 'guarantor', 'residence.duration', 'current.assets',
                      'other.credits', 'apartment.type', 'bank.credits', 'occupation', 
                      'dependents', 'telephone', 'foreign.worker')
dataset_credito_normalizado_factor <- factor_conversion(dataset_credito_normalizado, categorical_vars)
```


> 4) Realize a divisão do conjunto de treino e teste em 60/40.

```{r}
index_training = sample(1:nrow(dataset_credito_normalizado_factor), size = 0.6*nrow(dataset_credito_normalizado_factor))

training_data = dataset_credito_normalizado_factor[index_training,]
test_data     = dataset_credito_normalizado_factor[-index_training,]
test_features <- test_data[,-1]
test_target   <- test_data[,1]
```


> 5) Para reprodução dos resultados use o set.seed(100).


```{r}
set.seed(90)
```


> 6) Construa e treine o modelo preditivo de ML baseado em regressão logística.

```{r}
equation <- "credit.rating ~ ."
equation <- as.formula(equation)
modelo_ML_logistic_1 <- glm(equation, data = training_data, family = "binomial")
modelo_ML_logistic_1
```

> 7) Faça a síntese do modelo e interprete os seus resultados.

```{r}
summary(modelo_ML_logistic_1)
```

> 8) Faça as predições para os dados de teste e avalie os resultados com a matriz de confusão.

```{r}
previsao_teste <- predict(modelo_ML_logistic_1, test_data, type = 'response')
previsao_teste <- round(previsao_teste)
previsao_teste

previsao_teste_data <- data.frame(previsao_teste, test_target)
colnames(previsao_teste_data) <- c('Previsão','Target')
```

```{r}
cm_modelo_1 <- confusionMatrix(table(data = previsao_teste, reference = test_target), positive = "1")
cm_modelo_1
```



> 9) Use a função varImp do pacote caret para descobrir as variáveis explanatórias mais relevantes
para o modelo.

```{r}
feature_selection = varImp(modelo_ML_logistic_1, scale = TRUE)
# Visualização das variáveis explanatórias mais relevantes
feature_selection
```


> 10) Obtenha a curva ROC do classificador antes da análise varImp.

```{r}
# Função que podemos usar para plot da curva ROC 
plot.roc.curve <- function(predictions, title.text){
  perf <- performance(predictions, "tpr", "fpr")
  plot(perf,col = "black",lty = 1, lwd = 2,
       main = title.text, cex.main = 0.6, cex.lab = 0.8,xaxs = "i", yaxs = "i")
  abline(0,1, col = "red")
  auc <- performance(predictions,"auc")
  auc <- unlist(slot(auc, "y.values"))
  auc <- round(auc,2)
  legend(0.4,0.4,legend = c(paste0("AUC: ",auc)), cex = 0.6, bty = "n", box.col = "white")
}

# Plot - quantidade de gráficos na paleta gráfica do R
par(mfrow = c(1, 2))
previsoes_finais_modelo_1 <- prediction(previsao_teste, test_target)
plot.roc.curve(previsoes_finais_modelo_1, title.text = "Curva ROC (Modelo 1)")

```


> 11) Obtenha a curva ROC do classificador após da análise com varImp.

```{r}
equation_nova <- "credit.rating ~ account.balance + credit.purpose + previous.credit.payment.status + savings + credit.duration.months"
equation_nova <- as.formula(equation_nova)

modelo_ML_logistic_2 <- glm(equation_nova, data = training_data, family = "binomial")
modelo_ML_logistic_2

summary(modelo_ML_logistic_2)

previsao_teste_2 <- predict(modelo_ML_logistic_2, test_data, type = 'response')
previsao_teste_2 <- round(previsao_teste_2)

previsao_teste_2_data <- data.frame(previsao_teste_2, test_target)
colnames(previsao_teste_2_data) <- c('Previsão Nova','Target')

# Previsões do modelo de regressão logística 1
previsao_teste_modelo_2 <- predict(modelo_ML_logistic_2, test_data, type = 'response')
# previsao_teste_modelo_2 <- round(previsao_teste_modelo_2)

# Dataframe - previsão do modelo 2
# dataframe_previsao_modelo_2 <- data.frame(previsao_teste_modelo_2, test_target)
# colnames(dataframe_previsao_modelo_2) <- c('Previsão Nova','Target')
# View(dataframe_previsao_modelo_2)

# Repare na diferença entre a função predict e a função prediction
previsoes_finais_modelo_2 <- prediction(previsao_teste_modelo_2, test_target)

plot.roc.curve <- function(predictions, title.text){
  perf <- performance(predictions, "tpr", "fpr")
  plot(perf,col = "black",lty = 1, lwd = 2,
       main = title.text, cex.main = 0.6, cex.lab = 0.8,xaxs = "i", yaxs = "i")
  abline(0,1, col = "red")
  auc <- performance(predictions,"auc")
  auc <- unlist(slot(auc, "y.values"))
  auc <- round(auc,2)
  legend(0.4,0.4,legend = c(paste0("AUC: ",auc)), cex = 0.6, bty = "n", box.col = "white")
}

# Plot - quantidade de gráficos na paleta gráfica do R
plot.roc.curve(previsoes_finais_modelo_2, title.text = "Curva ROC (Modelo 2)")
```

